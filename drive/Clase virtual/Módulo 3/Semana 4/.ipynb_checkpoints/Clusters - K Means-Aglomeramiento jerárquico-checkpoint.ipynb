{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "acceptable-cement",
   "metadata": {},
   "source": [
    "# Clusters\n",
    " \n",
    "La clusterización es generar diferentes grupos de datos de forma tal que en cada grupo predomine una característica común y que esta difiera de los otros grupos. Esta es una técnica de **aprendizaje no supervisado** dado que, en principio, no sabemos qué datos pertenecen a cada grupo, y en muchos casos, ni siquiera sabemos cuántos grupos son. \n",
    "\n",
    "Los modelos de aprendizaje no-supervisado tienen los mismos pasos que el aprendizaje supervisado que vimos hasta este momento salvo por dos cuestiones: no se realiza la división de datos ni la evaluación.\n",
    "\n",
    "**No se realiza la división de los datos**, ya que no tenemos una variable a predecir **y** por lo cual no es necesario realizar esa división, tampoco se realiza la división en entrenamiento y testo porque no hay una predicción \"correcta\", sino solamente formas de organizar los datos.\n",
    "\n",
    "Existen formas de **evaluar** un modelo de aprendizaje no-supervisado pero no es con datos de testeo sino es con métricas propias de cada uno de los modelos\n",
    "\n",
    "Por lo tanto los pasos que realizaremos son:\n",
    "1. Definición del Problema\n",
    "2. Búsqueda de datos \n",
    "3. Exploración y Limpieza de Datos\n",
    "4. Entrenamiento del modelo\n",
    "\n",
    "\n",
    "##### Problema y Búsqueda de datos\n",
    "\n",
    "Uno de los usos más comunes de aprendizaje no-supervisado es la segmentación de clientes. En este caso vamos a utilizar un Dataset sobre Clientes de un Shopping para ver como podríamos realizar la segmentación.\n",
    "\n",
    "Vamos a utilizar un Dataset de [Kaggle](https://www.kaggle.com/vjchoudhary7/customer-segmentation-tutorial-in-python?select=Mall_Customers.csv)\n",
    "Con los mismo datos entrenaremos dos tipos de modelos distintos:\n",
    "- K-means (con distntos hiperárametros)\n",
    "- Aglomeración Jerarquica "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "arabic-electronics",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "english-remainder",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"Mall_Customers.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "following-stomach",
   "metadata": {},
   "source": [
    "##### Exploración y Limpieza del dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exclusive-resort",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "featured-wiring",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "opponent-merchant",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modificamos los nombres de las columnas\n",
    "\n",
    "data.columns =[\"id\", \"genero\", \"edad\", \"ingreso\", \"gasto\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unique-gauge",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizamos la relación entre las variables\n",
    "\n",
    "sns.pairplot(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "possible-angola",
   "metadata": {},
   "source": [
    "## Promedio-k (K-means)\n",
    "\n",
    "Esta es una de las técnicas más comunes y mas usadas, es un proceso iterativo en el cual se fijan la cantidad de cluster que se quieren generar y se crea el centroide (punto centro del cluster) de cada cluster en lugares aleatorios,  luego en cada iteración se toma la distancia de cada punto a su centroide más cercano, para cada cluster se computa el promedio de las distancias y se se actualiza el centroide con esa nueva posición, todo esto hasta, para cada cluster no cambién los integrantes del mismo o se cumplan un número fijo de iteraciones. \n",
    "\n",
    "En este caso lo primero que haremos será entrenar el modelo solamente utilizando las variables **ingreso** y **gastos** para poder visualizarlo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unique-delivery",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vamos a utilizar como datos ingreso y gastos\n",
    "\n",
    "data_clauster = data.drop(columns = [\"id\", \"edad\", \"genero\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unsigned-ballot",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_clauster.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "promising-farmer",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizamos los datos\n",
    "\n",
    "plt.figure(figsize = (7,7))\n",
    "sns.scatterplot(data = data_clauster, x = \"ingreso\", y = \"gasto\", s=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "selected-color",
   "metadata": {},
   "source": [
    "##### Entrenamiento del modelo\n",
    "\n",
    "No se realiza la división de los datos, directamente se entrena el modelo que se utilizará. \n",
    "\n",
    "Al momento de instanciar el modelo que se utilizará es necesario definir los hiperarámetros, en este caso la cantidad de cluster que deseamos formar (la cantidad de grupos). Podemos ver las opciones a definir en la [Documentación](https://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "varying-mediterranean",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importamos el modelo KMeans de la librería Scikit-Learn\n",
    "\n",
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "valuable-mongolia",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instanciamos el modelo definiendo los hiperparametros, en este caso 5: la cantidad de clausters que queremos buscar\n",
    "\n",
    "kmeans = KMeans(n_clusters=5, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "developing-magic",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrenamos el modelo con el método fit y TODOS los datos ya que no se realiza la división\n",
    "\n",
    "kmeans.fit(data_clauster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "arctic-employer",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Observamos las etiquetas creadas\n",
    "\n",
    "kmeans.labels_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fifteen-animal",
   "metadata": {},
   "source": [
    "##### Resultado del modelo\n",
    "\n",
    "Para poder observar mejor el resultado del modelo colocaremos las etiquetas obtenidas como una columna del Dataset. \n",
    "\n",
    "Veremos la distribución de los cluster creados y realizaremos una visualización de como quedo realizado el agrupamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "heavy-mambo",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Incorporamos una columna nueva en el DataFrame con las etiquetas\n",
    "\n",
    "data_clauster[\"cluster\"] = kmeans.labels_\n",
    "\n",
    "data_clauster.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "white-croatia",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obsevamos la cantidad de registos en cada clusters utilizando value_counts()\n",
    "\n",
    "data_clauster[\"cluster\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bright-musical",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizamos\n",
    "\n",
    "plt.figure(figsize = (7,7))\n",
    "sns.scatterplot(data = data_clauster, x = \"ingreso\", y = \"gasto\", hue=data_clauster[\"cluster\"].to_list(), palette=\"deep\", s=100)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "distributed-cooperation",
   "metadata": {},
   "source": [
    "#### Segundo modelo cambiando la cantidad de cluster\n",
    "\n",
    "Ahora entrenaremos otro modelo pero modificaremos el hiperparámetro n_cluster, es decir cambiaremos la cantidad de grupos que se buscaran."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "parental-invalid",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vamos a probar si seleccionamos 3 K\n",
    "\n",
    "data_3k = data.drop(columns = [\"id\", \"edad\", \"genero\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "announced-blues",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_3k.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tender-serve",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instanciamos el modelo definiendo los hiperparametros, en este caso 3 clausters\n",
    "\n",
    "kmeans_3k = KMeans(n_clusters=3, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "genuine-republican",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrenamos el modelo\n",
    "\n",
    "kmeans_3k.fit(data_3k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "breathing-bones",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Observamos las etiquetas creadas\n",
    "\n",
    "kmeans_3k.labels_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "affiliated-complaint",
   "metadata": {},
   "source": [
    "##### Resultado del modelo\n",
    "\n",
    "Para poder observar mejor el resultado del modelo colocaremos las etiquetas obtenidas como una columna del Dataset. \n",
    "\n",
    "Veremos la distribución de los cluster creados y realizaremos una visualización de como quedo realizado el agrupamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "promising-fiction",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Incorporamos una columna nueva en el DataFrame con las etiquetas\n",
    "\n",
    "data_3k[\"cluster\"] = kmeans_3k.labels_\n",
    "\n",
    "data_3k[\"cluster\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "supposed-nicholas",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obsevamos la cantidad de registos en cada clusters utilizando value_counts()\n",
    "\n",
    "data_3k[\"cluster\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fifty-production",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizamos\n",
    "\n",
    "plt.figure(figsize = (7,7))\n",
    "sns.scatterplot(data = data_3k, x = \"ingreso\", y = \"gasto\", hue=data_3k[\"cluster\"].to_list(), palette=\"deep\", s=100)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "general-riverside",
   "metadata": {},
   "source": [
    "#### Entrenamiento del modelo con todas las variables \n",
    "\n",
    "Ahora generaremos el claustering utilizando también las variables **edad** y **género**. Al utilizar más variables ya no es posible realizar las visualizaciones.\n",
    "\n",
    "Para poder utilizar la variable *género* primero es necesario convertirlo en variable dummy ya que es categórica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abroad-dinner",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vamos a utilizar como datos edad, ingresos, género y gastos\n",
    "\n",
    "data_completa = data.drop(columns = [\"id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "inclusive-history",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_completa = pd.get_dummies(data_completa,  drop_first=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "satisfied-volleyball",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_completa.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "funny-proof",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instanciamos el modelo definiendo los hiperparametros, en este caso 5: la cantidad de clausters que queresmos buscar\n",
    "\n",
    "kmeans = KMeans(n_clusters=5, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "herbal-westminster",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrenamos el modelo\n",
    "\n",
    "kmeans.fit(data_completa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "quarterly-preserve",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Observamos las etiquetas creadas\n",
    "\n",
    "kmeans.labels_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adopted-affairs",
   "metadata": {},
   "source": [
    "##### Resultado del modelo\n",
    "\n",
    "Para poder observar mejor el resultado del modelo colocaremos las etiquetas obtenidas como una columna del Dataset. \n",
    "\n",
    "Veremos la distribución de los cluster creados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "loving-desperate",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Incorporamos una columna nueva en el DataFrame con las etiquetas\n",
    "\n",
    "data_completa[\"cluster\"] = kmeans.labels_\n",
    "\n",
    "data_completa.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "utility-drain",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obsevamos la cantidad de registos en cada clusters utilizando value_counts()\n",
    "\n",
    "data_completa[\"cluster\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "perfect-narrative",
   "metadata": {},
   "source": [
    "## Aglomeración Jerárquica (Hierarchical Clustering)\n",
    "\n",
    "Ahora utilizaremos el mismo Dataset de Clientes de un Shopping para realizar el agrupamiento pero utilizaremos otro método llamado Aglomeración jerárquica.\n",
    "\n",
    "Este es un proceso iterativo, en el que en cada iteración, tomamos las distancias de todos los datos entre si, luego el par de puntos que se encuentren mas cerca se unen, de forma que ahora esos dos puntos forman un solo punto, y, su ubicación se obtiene de diferentes formas según el parámetro [linkage](https://scikit-learn.org/stable/modules/generated/sklearn.cluster.AgglomerativeClustering.html), esto se realiza hasta que solo quede un punto produciendo un dendograma, este se puede cortar a diferentes alturas para producir los clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "corresponding-brown",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creamos un DataFrame con las columnas \"ingreso\" y \"gasto\" para realizar nuevamente la clauserización\n",
    "\n",
    "data_aglomeracion = data.drop(columns = [\"id\", \"edad\", \"genero\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "humanitarian-private",
   "metadata": {},
   "source": [
    "##### Entrenamiento del modelo\n",
    "\n",
    "Al igual que antes, no se realiza la división de los datos, directamente se entrena el modelo que se utilizará. \n",
    "\n",
    "Al momento de instanciar el modelo que se utilizará es necesario definir los hiperarámetros, en este caso la *cantidad de cluster* que deseamos formar (la cantidad de grupos) y el tipo de *linkage*. Podemos ver las opciones a definir en la [Documentación](https://scikit-learn.org/stable/modules/generated/sklearn.cluster.AgglomerativeClustering.html?highlight=agglomerativeclustering#sklearn.cluster.AgglomerativeClustering).\n",
    "\n",
    "En este caso entrenaremos un modelo para realizar 5 cluster y se realizara utilizando el linkage \"average\", es decir, el promedio\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "competent-leeds",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importamos el modelo\n",
    "\n",
    "from sklearn.cluster import AgglomerativeClustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "processed-earthquake",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Instanciamos el modelo y definimos los hiperparametros: la cantidad de clauster y el tipo de linkage\n",
    "\n",
    "modelo_agg = AgglomerativeClustering(n_clusters=5, linkage = \"average\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cardiovascular-formula",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrenamos el modelo\n",
    "modelo_agg.fit(data_aglomeracion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "empirical-implement",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vemos las etiquetas creadas\n",
    "\n",
    "modelo_agg.labels_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "higher-stroke",
   "metadata": {},
   "source": [
    "##### Resultado del modelo\n",
    "\n",
    "Para poder observar mejor el resultado del modelo colocaremos las etiquetas obtenidas como una columna del Dataset. \n",
    "\n",
    "Veremos la distribución de los cluster creados y realizaremos una visualización de como quedo realizado el agrupamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mature-headquarters",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Incorporamos una columna con las etiquetas\n",
    "data_aglomeracion[\"cluster\"] = modelo_agg.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "focal-rhythm",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obsevamos la cantidad de registos en cada clusters utilizando value_counts()\n",
    "\n",
    "data_aglomeracion[\"cluster\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "affecting-router",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizamos\n",
    "\n",
    "plt.figure(figsize = (7,7))\n",
    "sns.scatterplot(data = data_aglomeracion, x = \"ingreso\", y = \"gasto\", hue=data_aglomeracion[\"cluster\"].to_list(), palette=\"deep\", s=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "turkish-merchandise",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizamos el dendograma\n",
    "\n",
    "from scipy.cluster.hierarchy import dendrogram, linkage, cophenet, fcluster\n",
    "\n",
    "Z = linkage(data_aglomeracion, 'average');\n",
    "\n",
    "plt.figure(figsize=[7,7])\n",
    "plt.title('Dendrogram')\n",
    "plt.xlabel('Index Numbers')\n",
    "plt.ylabel('Distance')\n",
    "dendrogram(\n",
    "    Z,\n",
    "    leaf_rotation=90.,  \n",
    "    leaf_font_size=5.,  \n",
    "    color_threshold=0,\n",
    "    truncate_mode='lastp'\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sustainable-senator",
   "metadata": {},
   "source": [
    "#### Segundo modelo cambiando la cantidad de cluster\n",
    "\n",
    "Ahora entrenaremos otro modelo pero modificaremos el hiperparámetro linkage por \"ward\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "solid-disorder",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Instanciamos el modelo y definimos los hiperparametros: la cantidad de clauster y el tipo de linkage\n",
    "\n",
    "modelo_agg_ward = AgglomerativeClustering(n_clusters=5, linkage = \"ward\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "restricted-catch",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrenamos el modelo\n",
    "modelo_agg_ward.fit(data_aglomeracion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ready-deposit",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vemos las etiquetas creadas\n",
    "\n",
    "modelo_agg_ward.labels_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "traditional-retro",
   "metadata": {},
   "source": [
    "##### Resultado del modelo\n",
    "\n",
    "Para poder observar mejor el resultado del modelo colocaremos las etiquetas obtenidas como una columna del Dataset. \n",
    "\n",
    "Veremos la distribución de los cluster creados y realizaremos una visualización de como quedo realizado el agrupamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "electrical-understanding",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Incorporamos una columna con las etiquetas\n",
    "data_aglomeracion[\"cluster_ward\"] = modelo_agg_ward.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "guilty-adventure",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obsevamos la cantidad de registos en cada clusters utilizando value_counts()\n",
    "\n",
    "data_3k[\"cluster\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unnecessary-opportunity",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizamos\n",
    "\n",
    "plt.figure(figsize = (7,7))\n",
    "sns.scatterplot(data = data_aglomeracion, x = \"ingreso\", y = \"gasto\", hue=data_aglomeracion[\"cluster_ward\"].to_list(), palette=\"deep\", s=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "occasional-tourist",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.cluster.hierarchy import dendrogram, linkage, cophenet, fcluster\n",
    "\n",
    "Z = linkage(data_aglomeracion, 'ward');\n",
    "\n",
    "plt.figure(figsize=[7,7])\n",
    "plt.title('Dendrogram')\n",
    "plt.xlabel('Index Numbers')\n",
    "plt.ylabel('Distance')\n",
    "dendrogram(\n",
    "    Z,\n",
    "    leaf_rotation=90.,  \n",
    "    leaf_font_size=5.,  \n",
    "    color_threshold=0,\n",
    "    truncate_mode='lastp'\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "anticipated-johnston",
   "metadata": {},
   "source": [
    "##### Conclusión\n",
    "\n",
    "Podríamos volver a entrenar un modelo de Agrupamiento Jerárquico con todas las variables del dataset. También podemos entrenar distintos modelos de K-Means o de Agrupamiento Jerárquico cambiando los hiperparámetros para observar los resutlados obtenidos y compararlos.\n",
    "\n",
    "Si bien no se realiza una evaluación con los datos de test, es posible evaluar el resultado del agrupamiento utilizando [Silhouette](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.silhouette_score.html?highlight=silhouette#sklearn.metrics.silhouette_score)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
