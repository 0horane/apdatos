{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "strategic-selection",
   "metadata": {},
   "source": [
    "Para poder visualizar los árboles de decisión que entrenaremos necesitamos instalar una librearía específica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "selected-bracket",
   "metadata": {},
   "outputs": [],
   "source": [
    "conda install python-graphviz"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "comprehensive-ridge",
   "metadata": {},
   "source": [
    "## Árbol de decisión\n",
    "\n",
    "Los árboles de decisión son modelos de Machine Learning que se pueden utilizar para **Clasificación** o para **Regresión**. En esta Notebook realizaremos un ejemplo de clasificación, y modificaremos hiperpárametros para ajustar los modelos.\n",
    "\n",
    "Realizaremos los pasos de todo Proyecto de Ciencia de Datos\n",
    "\n",
    "1. Definición del Problema\n",
    "2. Búsqueda de datos \n",
    "3. Exploración y Limpieza de Datos\n",
    "4. Dividir los datos en **X** (variables predictoras) e **y** (variable a predecir). Dividir los datos en entrenamiento y testo con el méodo *train_test_split*\n",
    "5. Entrenamiento del modelo\n",
    "6. Testeo del Modelo \n",
    "\n",
    "##### Definición del problema\n",
    "\n",
    "**¿Cuál será la especie de pinguino en base a determinadas características?**\n",
    "\n",
    "##### Búsqueda de datos\n",
    "\n",
    "El dataset que se utilizará es sobre Pinguinos donde se las variables predictoras son distintas características de los pinguinos y la variable a predecir es la *especie (\"species\")*. Fue extraído de [Kaggle](https://www.kaggle.com/datasets/resulcaliskan/penguins)\n",
    "\n",
    "Este dataset es una variación del extraído de https://www.openml.org/d/42585\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "detailed-acrylic",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importamos las librerías que utilizaremos\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "considered-paragraph",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"penguins.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "underlying-looking",
   "metadata": {},
   "source": [
    "##### Exploración y limpieza del dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "interested-defendant",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exposed-penny",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()\n",
    "\n",
    "# Vemos no hay datos nulos y hay 2 variables categóricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "attached-bankruptcy",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertimos en dummies las variables categóricas (no la variable a predecir)\n",
    "# Comenzamos con la variable sexo\n",
    "\n",
    "dummies_sex = pd.get_dummies(data=data[\"sex\"], drop_first=True, prefix = \"sex_\")\n",
    "data = data.join(dummies_sex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "raised-strengthening",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertimos la variable island\n",
    "\n",
    "dummies_island = pd.get_dummies(data=data[\"island\"], drop_first=True, prefix = \"island_\")\n",
    "data = data.join(dummies_island)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fantastic-irrigation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eliminamos las variables que reemplazamos por las dummies\n",
    "\n",
    "data.drop(columns= [\"sex\", \"island\"], inplace=True)\n",
    "data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "increasing-produce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vemos la distribución de la variable target\n",
    "\n",
    "data[\"species\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "negative-fellowship",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(data[\"species\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "chubby-lawrence",
   "metadata": {},
   "source": [
    "#### Entrenamiento del modelo\n",
    "\n",
    "Vamos a entrenar un modelo de Árbol de decisión para predecir la especie de Pinguino. En primer lugar dividermos los datos en **X** e **y** y en entrenamiento y testo.\n",
    "\n",
    "Instanciaremos el modelo de Árbol de decisión con los hiperparámentros por default."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "active-answer",
   "metadata": {
    "id": "preliminary-comparative"
   },
   "outputs": [],
   "source": [
    "# Generamos X e y \n",
    "\n",
    "X = data.drop(columns = \"species\")   #variables predictora\n",
    "y = data[\"species\"]   #variable a predecir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "present-swing",
   "metadata": {
    "id": "finished-scale"
   },
   "outputs": [],
   "source": [
    "# Dividimos datos en train y test\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=138)  #por default 25% de test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "intense-stretch",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importamos el modelo que utilizaremos\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "clinical-adult",
   "metadata": {
    "id": "japanese-gossip"
   },
   "outputs": [],
   "source": [
    "#Instanciamos el modelo que utilizaremosn en este caso con los hiperparámetros por default\n",
    "\n",
    "arbol = DecisionTreeClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "written-glossary",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "satisfactory-capability",
    "outputId": "220644a0-f766-4f2b-bd02-959df46ebb9d"
   },
   "outputs": [],
   "source": [
    "# Entrenamos el modelo \n",
    "\n",
    "arbol.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "assumed-little",
   "metadata": {},
   "source": [
    "##### Visualización del Árbol generado por el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sweet-criterion",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "class_names = ['Iris-setosa', 'Iris-versicolor', 'Iris-virginica']\n",
    "plt.figure(figsize = (15,15))\n",
    "tree.plot_tree(arbol, feature_names=data.columns[:-1],filled=True,rounded=True, class_names=class_names)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "following-receiver",
   "metadata": {},
   "source": [
    "##### Evaluación de datos de train\n",
    "\n",
    "En este caso, además de utilizar las métricas para evaluar los datos de testo, también utilizaremos las métricas para evaluar cómo el modelo fue entrenado, es decir, si utilizamos el método *predict* con los *X de entrenamiento* y comparamos con los *y de entrenamiento*. \n",
    "\n",
    "Esto no sirve para saber la performance del modelo ya que fue entrenado con los mismo datos, pero sirve para analizar cómo fue entrenado el modelo y, en el caso de los árboles de decisión, la exactitud con la que los datos se organizan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "devoted-establishment",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "y_pred_train = arbol.predict(X_train)\n",
    "exactitud_train_arbol = accuracy_score(y_train, y_pred_train)\n",
    "exactitud_train_arbol"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sixth-trust",
   "metadata": {},
   "source": [
    "Podemos observar que el resultado de evaluar los datos de entrenamiento es perfecta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wooden-equivalent",
   "metadata": {},
   "source": [
    "##### Probamos y evaluamos nuestro modelo\n",
    "\n",
    "Utilizamos el metodo *predict* para probar nuestro modelo con los datos de test. Luego comparamos la predicciones de nuestro modelo con el resultado real a través de una matrix de confusión y utilizando la métrica accuracy (exactitud)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "recent-agenda",
   "metadata": {
    "id": "agreed-library"
   },
   "outputs": [],
   "source": [
    "# Probamos nuestro modelo con los datos de test\n",
    "\n",
    "y_pred_arbol = arbol.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "expanded-cleveland",
   "metadata": {
    "id": "informal-intersection"
   },
   "outputs": [],
   "source": [
    "# Matriz de confusión:comparando resultado original (y_test) con predicción del modelo (y_pred_arbol_completo)\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "matriz_arbol = confusion_matrix(y_test, y_pred_arbol)\n",
    "sns.heatmap(matriz_arbol, annot=True)\n",
    "plt.xlabel(\"Etiquetas predichas\")\n",
    "plt.ylabel(\"Etiquetas reales\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "color-uruguay",
   "metadata": {
    "id": "rotary-hardware"
   },
   "outputs": [],
   "source": [
    "# Métrica accuracy\n",
    "\n",
    "exactitud_arbol = accuracy_score(y_test, y_pred_arbol)\n",
    "exactitud_arbol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sized-nicaragua",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"La exactitud del modelo árbol de decisión es\", round(exactitud_arbol,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "verbal-valley",
   "metadata": {},
   "source": [
    "#### Hiperparámetro distintos\n",
    "\n",
    "Al igual que el resto de los modelos vistos, también podemos entrenar modelos con distintos hiperparámetros para ver los resultados de los distintos modelos. Se puede ver en la [documentación](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html?highlight=tree#sklearn.tree.DecisionTreeClassifier).\n",
    "\n",
    "En el caso puntual de los algoritmos de árbol de decisión, estos tienen una tendencia al sobreajuste (overfitting), que lo veremos en profundidad la clase que viene. \n",
    "Para evitar eso es posible ajustar los distintos hiperpárametros para reducir la complejidad de los árboles, se utiliza un mecanismo denominado \"poda\", reduciendo el tamaño del árbol a través de limitar la profundidad máxima, limitar el número de muestraS requeridas por cada hoja o limitando el número mínimo de muestras para particionar. \n",
    "\n",
    "Algunos de los hiperparámetros que se pueden ajustar en el modelo de Scikit-Lear son:.\n",
    "\n",
    "- **max_depth:** profundidad máxima del árbol. Solemos determinar una profundidad máxima para evitar que el modelo sobreajuste.  \n",
    "- **min_samples_split:** número mínimo de muestras que un nodo debe contener para considerar la división. El valor predeterminado es dos. Podemos usar este parámetro para regularizar el árbol.\n",
    "- **min_samples_leaf:** número mínimo de muestras necesarias para ser considerado un nodo hoja. El valor predeterminado se establece en uno. Este parámetro se utiliza como una forma alternativa de limitar el crecimiento del árbol.  \n",
    "- **max_features:** número de características a considerar al buscar la mejor división. Si no se establece este valor, el árbol de decisión considerará todas las variables independientes disponibles para hacer la mejor división.\n",
    "\n",
    "En este caso vamos a entrenar y evaluar dos modelos modificando el hiperparámetro: \"max_depth\" y observando la diferencia a través de las visualizaciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wired-adobe",
   "metadata": {
    "id": "japanese-gossip"
   },
   "outputs": [],
   "source": [
    "# Instanciamos el modelo que utilizaremos con el hiperparámetro max_depth=4\n",
    "\n",
    "arbol_depth4 = DecisionTreeClassifier(max_depth=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "blond-crack",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "satisfactory-capability",
    "outputId": "220644a0-f766-4f2b-bd02-959df46ebb9d"
   },
   "outputs": [],
   "source": [
    "# Entrenamos el modelo \n",
    "\n",
    "arbol_depth4.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "retained-lawrence",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizamos el modelo entrenado\n",
    "\n",
    "class_names = ['Iris-setosa', 'Iris-versicolor', 'Iris-virginica']\n",
    "plt.figure(figsize = (10,10))\n",
    "tree.plot_tree(arbol_depth4, feature_names=data.columns[:-1],filled=True,rounded=True, class_names=class_names)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alpha-concrete",
   "metadata": {},
   "source": [
    "##### Evaluación de datos de train\n",
    "\n",
    "Podemos utilizar una métrica de evaluación para ver la performance del modelo con los datos de entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "selective-vintage",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_train_depth4 = arbol_depth4.predict(X_train)\n",
    "exactitud_train_depth4 = accuracy_score(y_train, y_pred_train_depth4)\n",
    "exactitud_train_depth4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "excess-cisco",
   "metadata": {},
   "source": [
    "##### Probamos y evaluamos nuestro modelo\n",
    "\n",
    "Utilizamos el metodo predict para probar nuestro modelo con los datos de test. Luego comparamos la predicciones de nuestro modelo con el resultado real a través de una matrix de confusión y utilizando la métrica accuracy (exactitud)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "centered-mambo",
   "metadata": {
    "id": "agreed-library"
   },
   "outputs": [],
   "source": [
    "# Probar nuestro modelo con los datos de test\n",
    "\n",
    "y_pred_depth4 = arbol_depth4.predict(X_test)\n",
    "y_pred_depth4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "powered-latex",
   "metadata": {
    "id": "informal-intersection"
   },
   "outputs": [],
   "source": [
    "# Matriz de confusión:comparando resultado original (y_test) con predicción del modelo (y_pred_depth4)\n",
    "matriz_depth4 = confusion_matrix(y_test, y_pred_depth4)\n",
    "sns.heatmap(matriz_depth4, annot=True)\n",
    "plt.xlabel(\"Etiquetas predichas\")\n",
    "plt.ylabel(\"Etiquetas reales\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "independent-continuity",
   "metadata": {
    "id": "rotary-hardware"
   },
   "outputs": [],
   "source": [
    "exactitud_depth4 = accuracy_score(y_test, y_pred_depth4)\n",
    "exactitud_depth4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "qualified-wholesale",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"La exactitud del modelo con los hiperparámetros por default es\", round(exactitud_arbol,2))\n",
    "print(\"La exactitud del modelo hiperparámetro profundidad máxima de 4 es\", round(exactitud_depth4,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "spoken-interim",
   "metadata": {},
   "source": [
    "#### Entrenamos nuestro modelo con otro hiperparámetro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "recreational-notebook",
   "metadata": {
    "id": "japanese-gossip"
   },
   "outputs": [],
   "source": [
    "# Instanciamos el modelo que utilizaremos con el hiperparámetro max_depth=2\n",
    "\n",
    "arbol_depth2 = DecisionTreeClassifier(max_depth=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "controversial-cassette",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "satisfactory-capability",
    "outputId": "220644a0-f766-4f2b-bd02-959df46ebb9d"
   },
   "outputs": [],
   "source": [
    "# Entrenamos el modelo \n",
    "\n",
    "arbol_depth2.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "connected-eugene",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizamos el modelo entrenado\n",
    "class_names = ['Iris-setosa', 'Iris-versicolor', 'Iris-virginica']\n",
    "plt.figure(figsize = (10,10))\n",
    "tree.plot_tree(arbol_depth2, feature_names=data.columns[:-1],filled=True,rounded=True, class_names=class_names)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "intelligent-court",
   "metadata": {},
   "source": [
    "##### Evaluación de datos de train\n",
    "\n",
    "Podemos utilizar una métrica de evaluación para ver la performance del modelo con los datos de entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "original-holocaust",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_train_depth2 = arbol_depth2.predict(X_train)\n",
    "exactitud_train_depth2 = accuracy_score(y_train, y_pred_train_depth2)\n",
    "exactitud_train_depth2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "young-grove",
   "metadata": {},
   "source": [
    "##### Probamos y evaluamos nuestro modelo\n",
    "\n",
    "Utilizamos el metodo predict para probar nuestro modelo con los datos de test. Luego comparamos la predicciones de nuestro modelo con el resultado real a través de una matrix de confusión y utilizando la métrica accuracy (exactitud)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "enabling-helicopter",
   "metadata": {
    "id": "agreed-library"
   },
   "outputs": [],
   "source": [
    "# Probar nuestro modelo con los datos de test\n",
    "\n",
    "y_pred_depth2 = arbol_depth2.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "external-cable",
   "metadata": {
    "id": "informal-intersection"
   },
   "outputs": [],
   "source": [
    "# Matriz de confusión:comparando resultado original (y_test) con predicción del modelo (y_pred_depth2)\n",
    "matriz_depth2 = confusion_matrix(y_test, y_pred_depth2)\n",
    "sns.heatmap(matriz_depth2, annot=True)\n",
    "plt.xlabel(\"Etiquetas predichas\")\n",
    "plt.ylabel(\"Etiquetas reales\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "further-highway",
   "metadata": {
    "id": "rotary-hardware"
   },
   "outputs": [],
   "source": [
    "# Métrica accuracy\n",
    "\n",
    "exactitud_depth2 = accuracy_score(y_test, y_pred_depth2)\n",
    "exactitud_depth2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "transparent-adrian",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparamos todos los modelos\n",
    "\n",
    "print(\"La exactitud del modelo con los hiperparámetros por default es\", round(exactitud_arbol,2))\n",
    "print(\"La exactitud del modelo con hiperparámetro profundidad máxima de 4 es\", round(exactitud_depth4,2))\n",
    "print(\"La exactitud del modelo con hiperparámetro profundidad máxima de 2 es\", round(exactitud_depth2,2))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
